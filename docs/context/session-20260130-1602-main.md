# Session Summary: 2026-01-30 - main

## Status: Completed

## Goals
- Design the rich media and story styling system for Zifmia (ADR-122 implementation)
- Resolve how to attach presentation metadata (illustrations, future media) to entities
- Create implementation plan for full UI/UX polish (themes, assets, styling)

## Completed

### Deep Architecture Review: Traits vs Annotations

**Critical finding**: The trait system cannot support multiple instances per entity. Traits use `Map<TraitType, ITrait>` — one per type, by design. This broke the original `IllustrationTrait` design from ADR-122, which assumed multiple illustrations per entity (panorama + detail, or conditional illustrations based on state).

**Research process**:
1. Read ADR-122 (Rich Media and Story Styling) which proposed `IllustrationTrait`
2. Explored current Zifmia UI state (themes working, CSS variables, all components styled)
3. Created initial 7-phase plan in `docs/work/zifmia/user-experience.md`
4. Identified that Phases 1-2 touched world-model and stdlib (platform changes)
5. User requested design review before implementation

**Key questions resolved**:
- Text-to-image association → `groupId` pairing between text and illustration events
- Multiple illustrations per entity → led to trait system limitation discovery
- Stateful illustrations → conditional annotation system
- Asset lifecycle → warn and clear on second story load
- CSS scoping → author can override anything (their responsibility)
- Error handling → author's problem
- Save/restore → annotations are static config, not game state
- Event system → no new phase needed, emit from `report()` alongside text events

### Entity Annotations Design

**Decision**: Illustrations (and future presentation metadata) should NOT be traits. They need a new system.

**Rationale**:
- Traits describe capabilities/behaviors the action system interacts with
- Illustrations are presentation metadata the engine never touches
- Trait one-per-type constraint blocks multiple illustrations
- Illustration data is static authored config — shouldn't pollute delta saves

**Annotation system features**:
- Multiple annotations per entity per kind (`Map<string, Annotation[]>`)
- Typed but open-ended kind system (illustration, portrait, voice, panel, map-icon, ambient)
- Condition system for stateful presentation (pure data, no callbacks)
- `groupId` pairing for text-to-image association
- Clean separation: annotations declare what's available, events declare what's shown

**Condition evaluation**:
```typescript
condition: { trait: 'switchable', property: 'isOn', value: true }
```
Checked against entity trait state at query time via `getActiveAnnotations()`. Supports `scope: 'self' | 'player' | 'location'` for cross-entity conditions.

**Event flow**:
- No new action phase needed
- `report()` phase emits `if.event.illustrated` alongside text events
- Shared helper `emitIllustrations(entity, trigger, groupId, context)`
- Looking action calls with trigger `on-enter`
- Examining action calls with trigger `on-examine`
- Story actions emit directly for transient effects (explosions, etc.)

**Re-illustration on state change**:
- Action causing the state change is responsible for emitting updated illustration events
- No global re-check mechanism (would be fragile and over-engineered)
- Examples: flood action emits updated room illustration, kill action emits updated troll illustration

### Future Vision: Multi-Actor Stories

User mentioned WIP "Reflections" story with 3 actors where the PC switches between them. Vision includes:
- Parallel text panels (each actor gets their own transcript column)
- Colored fonts per character
- Actor portraits in sidebar/header

The annotation system is designed to support this via:
- `voice` annotations → font color, typeface, CSS class per actor
- `panel` annotations → which transcript panel receives text
- `portrait` annotations → actor avatar image

None of this is implemented now, but the infrastructure doesn't preclude it.

### Documentation Created

**docs/work/zifmia/user-experience.md** (7-phase implementation plan):
1. Annotation infrastructure (world-model)
2. Illustration event emission (stdlib)
3. Asset map plumbing (Zifmia)
4. Client illustration rendering (Zifmia)
5. Story CSS scoping (Zifmia)
6. Player preferences (Zifmia)
7. CLI graceful degradation

**docs/architecture/adrs/adr-124-entity-annotations.md**:
- Comprehensive ADR superseding the `IllustrationTrait` design from ADR-122
- Documents the annotation system architecture
- Includes API design, condition system, event flow, save/restore strategy
- References ADR-122 for rendering and CSS decisions (still valid)

## Key Decisions

### 1. Annotations, Not Traits

Presentation metadata (illustrations, portraits, voice styling, etc.) belongs in a parallel system, not the trait system. Traits are for game-logic capabilities and behaviors. Annotations are for client-facing presentation hints the engine never touches.

**Implications**:
- Clean separation of concerns
- No delta save overhead for static presentation config
- Natural support for multiple per entity
- Extensible to future media kinds without architecture changes

### 2. Pure Data Conditions

Condition system uses pure data (trait/property/value checks), not callbacks. This enables:
- Serialization (if needed later)
- Evaluation at any time (query-time filtering via `getActiveAnnotations()`)
- No execution side effects

**Limitation**: Complex cross-entity conditions require story code to emit events directly. This is acceptable — the common case (single entity trait checks) is clean and simple.

### 3. Re-Illustration is Manual

The action causing a state change is responsible for emitting updated illustration events. There is no global "re-check all annotations" mechanism.

**Rationale**: Automatic re-checks would be fragile (when to trigger? which entities?) and over-engineered. The action that knows state changed can call `emitIllustrations()` easily.

**Trade-off**: Authors must remember to emit updated illustrations. Missed call = stale image. Accepted as reasonable author responsibility.

### 4. Event Flow: No New Phase

Media events emit from the existing `report()` phase alongside text events. The four-phase action pattern (validate/execute/report/blocked) already supports this.

**Finding**: After deep exploration of the report phase implementation, discovered that `report()` returns `ISemanticEvent[]` — it already returns an array of events, not just text events. Illustration events can simply be additional entries in that array.

### 5. Text-to-Image Association via groupId

Illustration events carry a `groupId` matching the associated text event's ID. This enables explicit client-side pairing for correct layout (float image alongside the right paragraph).

**Alternative considered**: Implicit association by order in the event array. Rejected because it's brittle (inserting other events breaks pairing) and doesn't support client flexibility (multiple images per text block, or vice versa).

## Open Items

### Short Term

**Awaiting user approval** before implementation:
- Annotation infrastructure (Phase 1) — touches world-model (platform change)
- Illustration event emission (Phase 2) — touches stdlib (platform change)

Once approved, implement Phases 1-2, then proceed with Zifmia client phases autonomously.

### Long Term

**Deferred design questions**:
- Runtime annotation mutation with save/restore support (if authors need to change illustrations mid-game)
- Complex condition expressions (OR, multiple traits, computed values) — story code can emit directly for now
- Multi-actor presentation system (voice, panel, portrait annotations) — designed-for but not implemented

**Testing needs**:
- Unit tests for conditional annotations (lantern lit/unlit)
- Integration test with `.sharpee` bundle containing assets and CSS
- State change test (flood changes room illustration mid-game)
- Save/restore test (conditional illustrations restore correctly)

## Files Modified

**Work plan** (1 file):
- `docs/work/zifmia/user-experience.md` — 7-phase implementation plan with full annotation design

**Architecture decision record** (1 file):
- `docs/architecture/adrs/adr-124-entity-annotations.md` — Comprehensive ADR for annotation system

**No code changes** — this was entirely design/planning work.

## Architectural Notes

### Trait System Constraint (Map<TraitType, ITrait>)

The trait system uses `Map<TraitType, ITrait>` on entities. This enforces one trait per type by design. The constraint is intentional — traits have singleton semantics (an entity is either openable or not, lockable or not, etc.).

This is the RIGHT design for game-logic capabilities. But it makes traits the WRONG place for presentation metadata that needs multiples (several illustrations, multiple voice styles for different moods).

### Report Phase Returns Event Array

Deep dive into action system revealed that `report()` already returns `ISemanticEvent[]`, not a single event. Looking action can return:
```typescript
return [
  context.event('if.event.looked', { roomId, description }),
  context.event('if.event.illustrated', { groupId, src, alt, ... }),
  context.event('if.event.illustrated', { groupId, src, alt, ... }),
  // ... more events
];
```

No new phase or event pipeline needed. The architecture already supports what we need.

### Compatibility with ADR-091 (Text Decorations)

Verified no conflicts between annotations and text decorations:
- Text decorations: Inline markup within paragraphs (`<em>`, `<strong>`, Markdown)
- Annotations: Block-level media (images, portraits, styling hints)

They operate at different layers. A room can have both styled text (decorations) and an illustration (annotation). The client renders both.

### Design Philosophy: Extend, Don't Invent

This session was a good example of "always trust the architecture." Initial instinct was to work around the trait constraint (multiple `IllustrationTrait` subclasses? an `IllustrationCollectionTrait`?). The right answer was to recognize that traits are the wrong abstraction entirely, and design a new system purpose-built for the use case.

The annotation system follows Sharpee's existing patterns:
- Parallel to traits (like events are parallel to actions)
- Pure data (like event payloads, not like behavior callbacks)
- Client interprets, engine ignores (like semantic events)
- Extensible via kind system (like action groups, trait types)

## Notes

**Session duration**: ~4 hours

**Approach**: Design review and planning session. User provided vision (rich media for Zifmia, future multi-actor stories), we collaboratively worked through 8 critical design questions, discovered the trait system limitation, and designed the annotation system as the solution.

**No code written** — entirely planning and ADR work. Platform changes (Phases 1-2) require user approval before implementation. Client phases (3-7) can proceed autonomously once approved.

**Next session**: Implement Phase 1 (annotation infrastructure in world-model) if approved, or switch to other Dungeo work if platform changes need more discussion.

---

**Progressive update**: Session completed 2026-01-30 16:02
